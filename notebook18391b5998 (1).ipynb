{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":95737,"sourceType":"datasetVersion","datasetId":51344}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch transformers datasets\n!pip install arabic_reshaper python-bidi ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:43:36.495263Z","iopub.execute_input":"2024-11-02T06:43:36.495728Z","iopub.status.idle":"2024-11-02T06:44:01.216841Z","shell.execute_reply.started":"2024-11-02T06:43:36.495675Z","shell.execute_reply":"2024-11-02T06:44:01.215604Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting arabic_reshaper\n  Downloading arabic_reshaper-3.0.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (0.6.0)\nDownloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\nInstalling collected packages: arabic_reshaper\nSuccessfully installed arabic_reshaper-3.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install transformers pandas arabic-reshaper python-bidi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:44:01.218257Z","iopub.execute_input":"2024-11-02T06:44:01.218597Z","iopub.status.idle":"2024-11-02T06:44:12.720703Z","shell.execute_reply.started":"2024-11-02T06:44:01.218565Z","shell.execute_reply":"2024-11-02T06:44:12.719799Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: arabic-reshaper in /opt/conda/lib/python3.10/site-packages (3.0.0)\nRequirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (0.6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/arabic-poetry-dataset-478-2017/all_poems.csv')  # Example file name\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:44:12.722238Z","iopub.execute_input":"2024-11-02T06:44:12.722575Z","iopub.status.idle":"2024-11-02T06:44:14.380832Z","shell.execute_reply.started":"2024-11-02T06:44:12.722541Z","shell.execute_reply":"2024-11-02T06:44:14.379941Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       poem_id                                          poem_link poem_style  \\\n0           21  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n1        65546  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n2        65561  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n3        65554  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n4        65550  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n...        ...                                                ...        ...   \n58016    86613  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n58017    86614  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n58018    86615  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n58019    86616  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n58020    86617  http://www.adab.com/modules.php?name=Sh3er&doW...       فصحى   \n\n                                               poem_text      poem_title  \\\n0      عيناك غابتا نخيل ساعة السحر او شرفتان راح يناي...   أنشودة المطر    \n1       انا لا ازال و في يدي قدحي ياليل اين تفرق الشر...  أقداح و أحلام    \n2       علي مقلتيك ارتشفت النجوم وعانقت امالي الايبة ...     هوى واحد !    \n3      اساطير من حشرجات الزمان نسيج اليد البالية رواه...         أساطير    \n4      والتف حولك ساعداي ومال جيدك في اشتهاء كالزهرة ...  اللقاء الأخير    \n...                                                  ...             ...   \n58016  لروح صهيل لا تحويه الاوقات ذنبك انك تمتد علي ا...          الوقت    \n58017  اه لو اني ابني الشمس بعيني من طين هواء وسراب م...         الفلاح    \n58018  في عينيك يا امي لماذا الدمع منتظم كعقد الءلء ا...           أمّي    \n58019  النوم يوقظ طرفي الظامي علي لحن تموج من بعيد ار...      عن اللحن     \n58020  السلم الذي نزلت فيه لسماء سلم من الجنان جاء او...          السلم    \n\n      poet_cat  poet_id                                          poet_link  \\\n0       العراق        2  http://www.adab.com/modules.php?name=Sh3er&doW...   \n1       العراق        2  http://www.adab.com/modules.php?name=Sh3er&doW...   \n2       العراق        2  http://www.adab.com/modules.php?name=Sh3er&doW...   \n3       العراق        2  http://www.adab.com/modules.php?name=Sh3er&doW...   \n4       العراق        2  http://www.adab.com/modules.php?name=Sh3er&doW...   \n...        ...      ...                                                ...   \n58016    سوريا      755  http://www.adab.com/modules.php?name=Sh3er&doW...   \n58017    سوريا      755  http://www.adab.com/modules.php?name=Sh3er&doW...   \n58018    سوريا      755  http://www.adab.com/modules.php?name=Sh3er&doW...   \n58019    سوريا      755  http://www.adab.com/modules.php?name=Sh3er&doW...   \n58020    سوريا      755  http://www.adab.com/modules.php?name=Sh3er&doW...   \n\n             poet_name  \n0      بدر شاكر السياب  \n1      بدر شاكر السياب  \n2      بدر شاكر السياب  \n3      بدر شاكر السياب  \n4      بدر شاكر السياب  \n...                ...  \n58016  عز الدين اليوسف  \n58017  عز الدين اليوسف  \n58018  عز الدين اليوسف  \n58019  عز الدين اليوسف  \n58020  عز الدين اليوسف  \n\n[58021 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>poem_id</th>\n      <th>poem_link</th>\n      <th>poem_style</th>\n      <th>poem_text</th>\n      <th>poem_title</th>\n      <th>poet_cat</th>\n      <th>poet_id</th>\n      <th>poet_link</th>\n      <th>poet_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>عيناك غابتا نخيل ساعة السحر او شرفتان راح يناي...</td>\n      <td>أنشودة المطر</td>\n      <td>العراق</td>\n      <td>2</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>بدر شاكر السياب</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>65546</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>انا لا ازال و في يدي قدحي ياليل اين تفرق الشر...</td>\n      <td>أقداح و أحلام</td>\n      <td>العراق</td>\n      <td>2</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>بدر شاكر السياب</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65561</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>علي مقلتيك ارتشفت النجوم وعانقت امالي الايبة ...</td>\n      <td>هوى واحد !</td>\n      <td>العراق</td>\n      <td>2</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>بدر شاكر السياب</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>65554</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>اساطير من حشرجات الزمان نسيج اليد البالية رواه...</td>\n      <td>أساطير</td>\n      <td>العراق</td>\n      <td>2</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>بدر شاكر السياب</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65550</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>والتف حولك ساعداي ومال جيدك في اشتهاء كالزهرة ...</td>\n      <td>اللقاء الأخير</td>\n      <td>العراق</td>\n      <td>2</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>بدر شاكر السياب</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58016</th>\n      <td>86613</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>لروح صهيل لا تحويه الاوقات ذنبك انك تمتد علي ا...</td>\n      <td>الوقت</td>\n      <td>سوريا</td>\n      <td>755</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>عز الدين اليوسف</td>\n    </tr>\n    <tr>\n      <th>58017</th>\n      <td>86614</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>اه لو اني ابني الشمس بعيني من طين هواء وسراب م...</td>\n      <td>الفلاح</td>\n      <td>سوريا</td>\n      <td>755</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>عز الدين اليوسف</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>86615</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>في عينيك يا امي لماذا الدمع منتظم كعقد الءلء ا...</td>\n      <td>أمّي</td>\n      <td>سوريا</td>\n      <td>755</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>عز الدين اليوسف</td>\n    </tr>\n    <tr>\n      <th>58019</th>\n      <td>86616</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>النوم يوقظ طرفي الظامي علي لحن تموج من بعيد ار...</td>\n      <td>عن اللحن</td>\n      <td>سوريا</td>\n      <td>755</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>عز الدين اليوسف</td>\n    </tr>\n    <tr>\n      <th>58020</th>\n      <td>86617</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>فصحى</td>\n      <td>السلم الذي نزلت فيه لسماء سلم من الجنان جاء او...</td>\n      <td>السلم</td>\n      <td>سوريا</td>\n      <td>755</td>\n      <td>http://www.adab.com/modules.php?name=Sh3er&amp;doW...</td>\n      <td>عز الدين اليوسف</td>\n    </tr>\n  </tbody>\n</table>\n<p>58021 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import re\ndef clean_poem(text):\n    if isinstance(text, str): \n        text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text) \n        text = re.sub(r'\\s+', ' ', text)\n        text = text.strip() \n        return text\n    return ''  \n\ndf['cleaned_poem'] = df['poem_text'].apply(clean_poem)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:44:14.383632Z","iopub.execute_input":"2024-11-02T06:44:14.384312Z","iopub.status.idle":"2024-11-02T06:44:19.872213Z","shell.execute_reply.started":"2024-11-02T06:44:14.384266Z","shell.execute_reply":"2024-11-02T06:44:19.871382Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"sample = df[['poem_text', 'cleaned_poem']].sample(frac=0.2, random_state=1)  # random_state for reproducibility\nprint(sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:44:19.873497Z","iopub.execute_input":"2024-11-02T06:44:19.873895Z","iopub.status.idle":"2024-11-02T06:44:19.896709Z","shell.execute_reply.started":"2024-11-02T06:44:19.873849Z","shell.execute_reply":"2024-11-02T06:44:19.895584Z"}},"outputs":[{"name":"stdout","text":"                                               poem_text  \\\n34015   تمسك بغيب الغيب واترك سواه لا سواه الي كم انت...   \n53758   الهي ذنوبي عدها ليس يحصر و من لي سوي الرحمن ي...   \n51306   اله اكبر يا سيلا من الغضب يا قاصفا من رياح ال...   \n57511   و اعتاد قلبي من الترحال لوعته ما عاد شيء من ا...   \n12376   وصف الصبر لي جهول بامري فارغ البال من همومي و...   \n...                                                  ...   \n32903   بدا ورنت لواحظه دلالا فما ابهي الغزالة والغزا...   \n52759  (1) الهي ارسل الي ذءبك الموت حتي يواجه قلبي ال...   \n34507   قالت وابثتها سري فبحت به قد كنت عندي تحب الست...   \n42162  اصغي ولكن لم يجد شيءا فقال افسر النص الغريب كم...   \n9377   في حلبة ذاتي بدا الثور يعربد متحنا بالشهوة اور...   \n\n                                            cleaned_poem  \n34015  تمسك بغيب الغيب واترك سواه لا سواه الي كم انت ...  \n53758  الهي ذنوبي عدها ليس يحصر و من لي سوي الرحمن يع...  \n51306  اله اكبر يا سيلا من الغضب يا قاصفا من رياح الن...  \n57511  و اعتاد قلبي من الترحال لوعته ما عاد شيء من ال...  \n12376  وصف الصبر لي جهول بامري فارغ البال من همومي وف...  \n...                                                  ...  \n32903  بدا ورنت لواحظه دلالا فما ابهي الغزالة والغزال...  \n52759  الهي ارسل الي ذءبك الموت حتي يواجه قلبي الاعزل...  \n34507  قالت وابثتها سري فبحت به قد كنت عندي تحب الستر...  \n42162  اصغي ولكن لم يجد شيءا فقال افسر النص الغريب كم...  \n9377   في حلبة ذاتي بدا الثور يعربد متحنا بالشهوة اور...  \n\n[11604 rows x 2 columns]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling, AdamW\nfrom tqdm import tqdm\nimport pandas as pd\ntokenizer = AutoTokenizer.from_pretrained('aubmindlab/aragpt2-base')\n\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained('aubmindlab/aragpt2-base')\n\ndef tokenize_poem(text):\n    return tokenizer.encode(text, truncation=True, padding='max_length', max_length=512)\n\nsample = df[['poem_text', 'cleaned_poem']].sample(frac=0.2, random_state=1)  \nsample['tokenized_poem'] = sample['cleaned_poem'].apply(tokenize_poem)\n\ntokenized_poems = sample['tokenized_poem'].tolist()\nn = int(len(tokenized_poems) * 0.8)\ntrain_data = torch.tensor(tokenized_poems[:n])  \nval_data = torch.tensor(tokenized_poems[n:])    \n\ncollator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False  \n)\n\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn=collator)\nval_loader = DataLoader(val_data, batch_size=8, shuffle=False, collate_fn=collator)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\ndef train_model(model, data_loader, optimizer, epochs=30):\n    model.train()  \n    for epoch in range(epochs):\n        loop = tqdm(data_loader, leave=True)  \n        total_loss = 0\n        for batch in loop:\n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            outputs = model(input_ids=batch['input_ids'], labels=batch['input_ids'])\n            loss = outputs.loss\n\n            # Backpropagation\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            total_loss += loss.item()\n            loop.set_description(f'Epoch {epoch + 1}')\n            loop.set_postfix(loss=loss.item())\n\n        print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {total_loss / len(data_loader)}\")\n\ntrain_model(model, train_loader, optimizer, epochs=27)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:44:19.897916Z","iopub.execute_input":"2024-11-02T06:44:19.898228Z","iopub.status.idle":"2024-11-02T17:08:51.481564Z","shell.execute_reply.started":"2024-11-02T06:44:19.898192Z","shell.execute_reply":"2024-11-02T17:08:51.480615Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7504f364943d47a784cd06c1b8643fb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11b22cc8fa39432d8f4f883292229511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.50M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deb8b20b65a94dd7935510ac30296725"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.52M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"767bab153e8347fd81dc5f1a7f0701e1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c63ea7fd42dc434cb2aabd9e55f57ad6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nEpoch 1: 100%|██████████| 1161/1161 [23:02<00:00,  1.19s/it, loss=4.09] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/27, Average Loss: 2.5065610416997206\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=0.891]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/27, Average Loss: 2.335397533770782\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 1161/1161 [23:05<00:00,  1.19s/it, loss=2.65] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/27, Average Loss: 2.2697091929928996\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.45] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/27, Average Loss: 2.217819104771692\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=2.74] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/27, Average Loss: 2.173224858407005\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 1161/1161 [23:05<00:00,  1.19s/it, loss=2.41] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/27, Average Loss: 2.1317370111679437\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=0.666]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/27, Average Loss: 2.090992628090552\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.01] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/27, Average Loss: 2.053750773861324\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.87] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/27, Average Loss: 2.0174018215712137\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.53] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/27, Average Loss: 1.9821208920281679\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.24] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/27, Average Loss: 1.947580117279861\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=2.52] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/27, Average Loss: 1.9149656471869332\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=0.395]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/27, Average Loss: 1.8808510651319423\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=2.18] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/27, Average Loss: 1.8496174651112256\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=0.485]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/27, Average Loss: 1.816169573714464\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=0.345]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/27, Average Loss: 1.7834863439138136\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=2.31] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/27, Average Loss: 1.7520805824737318\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=0.794]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/27, Average Loss: 1.7192931305889834\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=2.1]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/27, Average Loss: 1.6873561152089371\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.96] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/27, Average Loss: 1.6550561731278537\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=3.18] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/27, Average Loss: 1.6233794665177457\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=2.25] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/27, Average Loss: 1.5896894998020596\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=0.975]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/27, Average Loss: 1.5561589084751744\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.36] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/27, Average Loss: 1.523790828915735\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=2]    \n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/27, Average Loss: 1.4918228546727021\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.26] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/27, Average Loss: 1.4584119451343756\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27: 100%|██████████| 1161/1161 [23:06<00:00,  1.19s/it, loss=1.19] ","output_type":"stream"},{"name":"stdout","text":"Epoch 27/27, Average Loss: 1.426709779319221\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"vhgvftredtrdtyrfuytou[piotu6ruy7hhhhhhfrd56euyhhhhhhhh]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\n\ndef calculate_perplexity(model, data_loader):\n    model.eval()  \n    total_loss = 0\n    num_batches = len(data_loader)\n\n    if num_batches == 0:\n        print(\"Warning: DataLoader is empty!\")\n        return float('inf') \n    \n    with torch.no_grad():  \n        for batch in data_loader:\n            if isinstance(batch, dict):\n                input_ids = batch['input_ids'].to(model.device)  \n            else:\n                input_ids = batch.to(model.device)  \n\n            outputs = model(input_ids=input_ids, labels=input_ids)  \n            loss = outputs.loss\n            total_loss += loss.item()\n    \n    avg_loss = total_loss / num_batches\n    \n    perplexity = math.exp(avg_loss)\n    return perplexity\n\n# Example usage:\ntrain_perplexity = calculate_perplexity(model, train_loader)\nval_perplexity = calculate_perplexity(model, val_loader)\n\nprint(f\"Training Perplexity: {train_perplexity}\")\nprint(f\"Validation Perplexity: {val_perplexity}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T17:08:51.482998Z","iopub.execute_input":"2024-11-02T17:08:51.483644Z","iopub.status.idle":"2024-11-02T17:17:19.692470Z","shell.execute_reply.started":"2024-11-02T17:08:51.483609Z","shell.execute_reply":"2024-11-02T17:17:19.691618Z"}},"outputs":[{"name":"stdout","text":"Training Perplexity: 2.871025069328815\nValidation Perplexity: 10.911312003655167\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\n\ndef generate_poem(model, tokenizer, prompt, max_length=50):\n    model.eval()  \n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n        inputs.input_ids,\n        max_length=max_length,\n        num_return_sequences=1,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    generated_poem = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return generated_poem\n\n# Function to conduct user testing\ndef user_testing(model, tokenizer, prompts, max_length=50):\n    feedback_list = []\n\n    print(\"Welcome to the poetry generation feedback session!\")\n    print(\"You will be shown several poems generated by our model.\")\n\n    for i, prompt in enumerate(prompts):\n        print(f\"\\nPrompt {i+1}: {prompt}\")\n        generated_poem = generate_poem(model, tokenizer, prompt, max_length=max_length)\n        print(f\"\\nGenerated Poem:\\n{generated_poem}\")\n\n        # Collect feedback\n        print(\"\\nPlease rate the poem on the following aspects:\")\n        fluency = input(\"Fluency (1-5): \")\n        creativity = input(\"Creativity (1-5): \")\n        coherence = input(\"Coherence (1-5): \")\n        overall = input(\"Overall (1-5): \")\n\n        # Collect suggestions for improvement\n        improvement_suggestions = input(\"What would you suggest for improving the poem? \")\n\n        # Store the feedback\n        feedback = {\n            \"prompt\": prompt,\n            \"generated_poem\": generated_poem,\n            \"fluency\": fluency,\n            \"creativity\": creativity,\n            \"coherence\": coherence,\n            \"overall\": overall,\n            \"improvement_suggestions\": improvement_suggestions\n        }\n        feedback_list.append(feedback)\n\n    return feedback_list\n\nprompts = [\n    \"عيناك غابتا نخيل\",\n    \"أنا لا أزال وفي يدي قمر\",\n    \"أحببتك رغم الغياب\"\n]\n\n# Conduct user testing\nfeedback = user_testing(model, tokenizer, prompts)\n\n# Print feedback summary\nfor i, fb in enumerate(feedback):\n    print(f\"\\nFeedback for Prompt {i+1}:\")\n    print(f\"Fluency: {fb['fluency']}, Creativity: {fb['creativity']}, Coherence: {fb['coherence']}, Overall: {fb['overall']}\")\n    print(f\"Suggestions: {fb['improvement_suggestions']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T17:24:56.318485Z","iopub.execute_input":"2024-11-02T17:24:56.318848Z","iopub.status.idle":"2024-11-02T17:25:16.682238Z","shell.execute_reply.started":"2024-11-02T17:24:56.318812Z","shell.execute_reply":"2024-11-02T17:25:16.681319Z"}},"outputs":[{"name":"stdout","text":"Welcome to the poetry generation feedback session!\nYou will be shown several poems generated by our model.\n\nPrompt 1: عيناك غابتا نخيل\n\nGenerated Poem:\nعيناك غابتا نخيل العراق عن عينيهما وانا وحيد في الغربة اساءل كيف استطعت ان اسرق من عينيك قصيدة وجعلت قلبي من عينيك قصيدة وجعلت قلبي من عينيك قصيدة وجعلت قلبي من عينيك قصيدة وجعلت قلبي من عينيك قصيدة وجعلت قلبي من عينيك قصيدة\n\nPlease rate the poem on the following aspects:\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Fluency (1-5):  5\nCreativity (1-5):  5\nCoherence (1-5):  5\nOverall (1-5):  5\nWhat would you suggest for improving the poem?  5\n"},{"name":"stdout","text":"\nPrompt 2: أنا لا أزال وفي يدي قمر\n\nGenerated Poem:\nأنا لا أزال وفي يدي قمرا ينير بي من دون ان ادري اذا كنت انت الذي كنته وانا الذي كنته وانا الذي كنته وانا الذي كنته وانا الذي كنته وانا الذي كنته وانا الذي كنته وانا الذي كنته وانا الذي\n\nPlease rate the poem on the following aspects:\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Fluency (1-5):  5\nCreativity (1-5):  5\nCoherence (1-5):  5\nOverall (1-5):  5\nWhat would you suggest for improving the poem?  5\n"},{"name":"stdout","text":"\nPrompt 3: أحببتك رغم الغياب\n\nGenerated Poem:\nأحببتك رغم الغياب ورغم الغياب ورغم الحضور ورغم الحضور المكثف ورغم الحضور المكثف ورغم الحضور المكثف ورغم الحضور المكثف وطول ارتيادي في الحضور المكثف ورغم الحضور المكثف وطول ارتيادي في الحضور المكثف ورغم الحضور المكثف وطول ارتيادي في الحضور المكثف واحسنت حظي من\n\nPlease rate the poem on the following aspects:\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Fluency (1-5):  5\nCreativity (1-5):  5\nCoherence (1-5):  5\nOverall (1-5):  5\nWhat would you suggest for improving the poem?  5\n"},{"name":"stdout","text":"\nFeedback for Prompt 1:\nFluency: 5, Creativity: 5, Coherence: 5, Overall: 5\nSuggestions: 5\n\nFeedback for Prompt 2:\nFluency: 5, Creativity: 5, Coherence: 5, Overall: 5\nSuggestions: 5\n\nFeedback for Prompt 3:\nFluency: 5, Creativity: 5, Coherence: 5, Overall: 5\nSuggestions: 5\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\n\ndef calculate_bleu_score(generated_texts, reference_texts):\n    # Ensure the lengths of the two lists are the same\n    assert len(generated_texts) == len(reference_texts), \"The number of hypotheses and references must be the same\"\n\n    # Tokenize the texts\n    reference_corpus = [[ref.split()] for ref in reference_texts] \n    generated_corpus = [gen.split() for gen in generated_texts] \n    # Calculate BLEU score\n    score = corpus_bleu(reference_corpus, generated_corpus)\n    return score\n\n\ngenerated_poems = [\"عيناك غابتا نخيل العراق عن عينيهما وانا وحيد في الغربة اساءل كيف استطعت ان اسرق من عينيك قصيدة وجعلت قلبي من عينيك قصيدة وجعلت قلبي من عينيك قصيدة وجعلت قلبي من عينيك قصيدة وجعلت قلبي من عينيك قصيدة وجعلت قلبي من عينيك قصيدة\"]  # Example generated texts\nreference_poems = [\"عيناك غابتا نخيل\"]  # Example reference texts\n\nbleu_score = calculate_bleu_score(generated_poems, reference_poems)\nprint(f\"BLEU Score: {bleu_score}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T17:26:16.167303Z","iopub.execute_input":"2024-11-02T17:26:16.167708Z","iopub.status.idle":"2024-11-02T17:26:17.073931Z","shell.execute_reply.started":"2024-11-02T17:26:16.167659Z","shell.execute_reply":"2024-11-02T17:26:17.073023Z"}},"outputs":[{"name":"stdout","text":"BLEU Score: 0.0948773207091217\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 4-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}],"execution_count":12}]}